{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1mKJrMNEH1kdJ-CiPtYSrYCJx9ooFrOfV",
      "authorship_tag": "ABX9TyOnTnjnar0VPAJvxKicj06C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Munazza-Farees/NITW-SIP2025-Project/blob/main/WS_GTC_FL_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWL0SN60dlYx",
        "outputId": "4733069d-2203-4282-f023-7d6b5076f8e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.6/87.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install numpy pandas torch sklearn --quiet\n",
        "!pip install kymatio --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from kymatio.torch import Scattering1D\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "qZ_ZwEIa04P6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "URL = \"/content/drive/MyDrive/Datasets/crosslayer_ldos_dataset_filtered2.csv\"\n",
        "data = pd.read_csv(URL)"
      ],
      "metadata": {
        "id": "4LjL3vI01kCI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select relevant features for wavelet scattering (time-series and statistical)\n",
        "features = [\n",
        "    'packet_rate', 'byte_rate', 'inter_arrival_mean', 'inter_arrival_std',\n",
        "    'flow_duration', 'length_mean', 'length_std', 'packet_size_std',\n",
        "    'tcp_syn_count', 'tcp_ack_count', 'tcp_flag_entropy', 'rtt_mean', 'rtt_std',\n",
        "    'payload_entropy', 'source_entropy'\n",
        "]\n",
        "\n",
        "X = data[features].values\n",
        "y = data['label'].values\n",
        "\n",
        "X = np.nan_to_num(X, nan=np.mean(X, axis=0))\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n"
      ],
      "metadata": {
        "id": "4HWE0SLnlmRg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.long)\n",
        "y_test = torch.tensor(y_test, dtype=torch.long)"
      ],
      "metadata": {
        "id": "q798Hi8JmQld"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up Wavelet Scattering\n",
        "J = 2    # Invariance scale\n",
        "Q = 8     # Quality factor (number of wavelets per octave)\n",
        "T = X_train.shape[1]      # Length of input signal (number of features)\n",
        "scattering = Scattering1D(J, T, Q)\n",
        "\n",
        "X_train_scattering = scattering(X_train)\n",
        "X_test_scattering = scattering(X_test)\n",
        "\n",
        "X_train_scattering = X_train_scattering.view(X_train_scattering.size(0), 1, -1)\n",
        "X_test_scattering = X_test_scattering.view(X_test_scattering.size(0), 1, -1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PQk0BG9mrOx",
        "outputId": "d657cfc2-d90c-4f53-ee31-c108c9f0ca6b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/kymatio/scattering1d/filter_bank.py:218: UserWarning: Signal support is too small to avoid border effects\n",
            "  warnings.warn('Signal support is too small to avoid border effects')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Define CNN model\n",
        "class LDOS_CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LDOS_CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=32, kernel_size=3)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
        "        # Calculate output size after conv and pool\n",
        "        sequence_length = X_train_scattering.shape[2] - 2  # After conv1 (kernel_size=3)\n",
        "        sequence_length = sequence_length // 2  # After max pooling (kernel_size=2)\n",
        "        self.fc_input_size = 32 * sequence_length\n",
        "        self.fc1 = nn.Linear(self.fc_input_size, 64)\n",
        "        self.fc2 = nn.Linear(64, 2)  # 2 classes: normal, attack\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        x = x.view(x.size(0), -1)  # Flatten\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "# Explanation:\n",
        "# - Defines a 1D CNN with one convolutional layer (32 filters), ReLU, and max-pooling.\n",
        "# - Updates fc_input_size calculation to match reshaped scattering output.\n",
        "# - Forward pass processes input through conv, pool, and fully connected layers.\n",
        "\n",
        "# Initialize model, loss function, and optimizer\n",
        "model = LDOS_CNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "# Explanation: Initializes CNN, uses CrossEntropyLoss for binary classification, and Adam optimizer.\n",
        "\n",
        "# 4. Train the model\n",
        "num_epochs = 20\n",
        "batch_size = 32\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for i in range(0, X_train_scattering.shape[0], batch_size):\n",
        "        inputs = X_train_scattering[i:i+batch_size]\n",
        "        labels = y_train[i:i+batch_size]\n",
        "\n",
        "        optimizer.zero_grad()  # Clear gradients\n",
        "        outputs = model(inputs)  # Forward pass\n",
        "        loss = criterion(outputs, labels)  # Compute loss\n",
        "        loss.backward()  # Backpropagation\n",
        "        optimizer.step()  # Update weights\n",
        "    print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
        "# Explanation: Trains model for 20 epochs, processing batches of size 32, computing loss, and updating weights.\n",
        "\n",
        "# 5. Evaluate the model\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = model(X_test_scattering)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    accuracy = (predicted == y_test).float().mean()\n",
        "    print(f'Test Accuracy: {accuracy.item()*100:.2f}%')\n",
        "# Explanation: Evaluates model on test data and computes accuracy.\n",
        "\n",
        "# 6. Save the model\n",
        "torch.save(model.state_dict(), '/content/drive/MyDrive/Models/cnn_ldos_model.pth')\n",
        "# Explanation: Saves trained model weights to a file."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12i5JTepn1rY",
        "outputId": "f77decc4-da80-4c0d-bf06-c4266eb4ab87"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.5417799949645996\n",
            "Epoch 2, Loss: 0.3870615065097809\n",
            "Epoch 3, Loss: 0.23589277267456055\n",
            "Epoch 4, Loss: 0.10661576688289642\n",
            "Epoch 5, Loss: 0.054958608001470566\n",
            "Epoch 6, Loss: 0.0417223758995533\n",
            "Epoch 7, Loss: 0.03819148242473602\n",
            "Epoch 8, Loss: 0.036348067224025726\n",
            "Epoch 9, Loss: 0.035300083458423615\n",
            "Epoch 10, Loss: 0.03541140258312225\n",
            "Epoch 11, Loss: 0.03405031934380531\n",
            "Epoch 12, Loss: 0.03348416090011597\n",
            "Epoch 13, Loss: 0.034156907349824905\n",
            "Epoch 14, Loss: 0.03457849472761154\n",
            "Epoch 15, Loss: 0.034485042095184326\n",
            "Epoch 16, Loss: 0.03493461385369301\n",
            "Epoch 17, Loss: 0.035082992166280746\n",
            "Epoch 18, Loss: 0.03500992804765701\n",
            "Epoch 19, Loss: 0.03506786748766899\n",
            "Epoch 20, Loss: 0.03506803140044212\n",
            "Test Accuracy: 96.36%\n"
          ]
        }
      ]
    }
  ]
}